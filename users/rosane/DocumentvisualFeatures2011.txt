2011 IEEE International Conferences on Internet of Things, and Cyber, Physical and Social Computing

Document Clustering Method Based on
Visual Features
Yucong Liu, Bofeng Zhang, Kun Xing, Bo Zhou
School of Computer Engineering & Science
Shanghai University
Shanghai, China
e-mail: liuyucong@163.com, bfzhang@shu.edu.cn

information resources. In this paper we focus on document
clustering.
At present, as millions of scientific documents available
on the Web. Indexing or searching millions of documents
and retrieving the desired information has become an increasing challenge and opportunity with the rapid growth of
scientific documents. Clustering plays an important role in
analysis of user interests in user model. So high-quality
scientific document clustering plays a more and more important role in the real word applications such as personalized
service and recommendation systems.
Clustering is a classical method in data mining research.
Scientific document clustering [6][8][9] is a technique which
puts related papers into a same group. The documents within
each group should exhibit a large degree of similarity while
the similarity among different clusters should be minimized.
In general, there are lots of algorithms about clustering
[1][5][10][13], including partitioning methods[5] (k-means,
k-medoids etc), hierarchical methods [16] (BIRCH, CURE,
etc), density-based methods (DBSCAN, OPTICS, etc), gridbased methods (STING, CLIQUE, etc) and model-based
methods, etc.
In 1967, MacQueen first put forward the k-means
[2][3][4][7] clustering algorithm.The k-means method has
shown to be effective in producing good clustering results
for many practical applications. However it suffers from
some major drawbacks that make it inappropriate for some
applications. One major disadvantage is that the number of
cluster k must be specified prior to application. And another
is the sensitivity to initialization. The two drawbacks of kmeans not only affect the efficiency of the algorithm but also
influence clustering accuracy.
There are many existing document representation approaches [11], including Boolen Approach, Vector Space
Model (VSM), Probabilistic Retrieval Model and Language
Model. At present the most popular document representation
is Vector Space Model (VSM). In the 1960’s, G. Salton and
other people proposed VSM. VSM is an algebraic model for
representing text documents as vectors of identifiers. Documents
are
represented
as
vectors,
such
as
 = ( ,  , … ,  , … ,  ). The main advantages of this

Abstract—There are two important problems worth conducting research in the fields of personalized information services
based on user model. One is how to get and describe user personal information, i.e. building user model, the other is how to
organize the information resources, i.e. document clustering. It
is difficult to find out the desired information without a proper
clustering algorithm. Several new ideas have been proposed in
recent years. But most of them only took into account the text
information, but some other useful information may have more
contributions for documents clustering, such as the text size,
font and other appearance characteristics, so called visual features. This paper proposes a method to cluster the scientific
documents based on visual features, so called VF-Clustering
algorithm. Five kinds of visual features of documents are defined, including body, abstract, subtitle, keyword and title. The
thought of crossover and mutation in genetic algorithm is used
to adjust the value of k and cluster center in the k-means algorithm dynamically. Experimental result supports our approach
as better concept. In the five visual features, the clustering
accuracy and steadiness of subtitle are only less than that of
body, but the efficiency is much better than body because the
subtitle size is much less than body size. The accuracy of clustering by combining subtitle and keyword is better than each
of them individually, but is a little less than that by combining
subtitle, keyword and body. If the efficiency is an essential
factor, clustering by combining subtitle and keyword can be an
optimal choice.
Keywods-document clustering; k-means; visual features;
genetic algorithm

I.

INTRODUCTION

In recent years, personalized information services play an
important role in people’s life. There are two important problems worth researching in the fields. One is how to get and
describe user personal information, i.e. building user model,
the other is how to organize the information resources, i.e.
document clustering. Personal information is described exactly only if user behavior and the resource what they look
for or search have been accurately analyzed. The effectiveness of a personalized service depends on completeness and
accuracy of user model. The basic operation is organizing the

978-0-7695-4580-6/11 $26.00 © 2011 IEEE
DOI 10.1109/iThings/CPSCom.2011.69

458

representation are its conceptual simplicity and its efficiency
of similarity computation. Its main disadvantage is the fact
that it loses important information about the original document.The classic vector space model proposed by Salton,
Wong and Yang. The model is known as term frequencyinverse document frequency model (TF-IDF) [12]. In document clustering, the document size is not taken into account
when calculating the weight of clustering keywords using
TF-IDF.
The most important goal of this paper is to develop a
technique which will guide the user to get desired information with proper clustering of scientific documents in web or
information retrieval systems. In this paper we propose a
high performance document clustering algorithm (called VFClustering) based on document’s visual features, including
body, abstract, subtitle, keyword and title. We integrate several visual features to represent documents. We also use the
thought of crossover and mutation in genetic algorithm
[14][15] to improve the k-means algorithm. We merge and
add cluster centers during the process of clustering to adjust
the value of k and cluster center dynamically. Experimental
result shows that our approach is better in terms of clustering
performance of the scientific documents.
The paper is organized as follows. Section 2 expresses
the key steps of document clustering. Section 3 presents the
document clustering algorithm based on visual features. Section 4 shows the implementation of VF-Clustering in Chinese scientific document clustering. Section 5 concludes the
paper.
II.



 =

! ()

, _  . !"




#$%()





where size (i) means the number of effective characters of
! #$%(&)

shows the average size of all
the i-th documentˈ !"
'
the document in date set, 
*+, 
_  expresses the words
occurrence frequency of keyword 
_ appeared in document
 , m is the number of documents containing 
_ , and N is
the total number of document contained in a document set.
C. Similarity Measurement
After the document representation using VSM, a document can be represented by a point in n-dimensional space,
while the similarity measurement between different documents was represented by the distance between corresponding points. The closer the distance between the two points is
in n-dimensional, the more similar the documents
represented by the two points is, and vice versa. To calculate
the distance, there are many different methods, such as Mahalanobis distance and Euclidean distance, etc. The more
similar two documents is, the more similar coefficient close
to 1, conversely, the similar coefficient is close to 0. In this
paper, documents’ similarity here is presented by cosine similarity which is defined by (3).


-/0(+, 1) =

2 32
||2 ||3||2 ||





For exampleˈ
 = (1,2,2,1,0)ˈ = (0,1,2,1,1)
 3  = 1  0 + 2  1 + 2  2 + 1  1 + 0  1 = 7
|| || = 09:
(1  1 + 2  2 + 2  2 + 1  1 + 0  0)
|| || = 09:
(0  0 + 1  1 + 2  2 + 1  1 + 1  1)
7
= ;0.7
-/0(+, 1) =
;10  ;7

KEY STEPS OF DOCUMENT CLUSTERING

A. Document Segmentation
As it is necessary to segment document into words before
document feature extraction, in our research, we use lexiconbased Word segmentation tools of the ICTCLAS (Institute of
Computing Technology, Chinese Lexical Analysis System).
However, its lexicon version is too low so that we add a
large amount of new words into this lexicon and remove stop
words from the result set of words segmentation.

III.

B. Document Representation and Feature-Words Selection
As we know, Vector Space Model (VSM) is widely used
in document clustering, in which each n-dimensional vector
represents a document. In this paper, VSM can be
represented as (1).

DOCUMENT CLUSTERING ALGORITHM BASED ON
VISUAL FEATURES

The main characteristics of document clustering algorithm based on visual features, so called VF-Clustering are as
follows:
1) Five kinds of visual features are defined according to
the analysis of content and structure of scientific document,
including body (B), abstract (A), subtitle (S), keyword (K)
and title (T). And the importance of these features to scientific document clustering will be compared through experiments.
2) In view of the two drawbacks of k-means algorithm,
the thought of crossover and mutation in genetic algorithm is
used to improve the k-means algorithm. Adjust the values of
k and cluster center dynamically by merging and adding
cluster centers in the process of clustering.
The implementation of clustering algorithm introduces
below.

d	 = ((t 	 , w	 ), (
 ,  ), … , (
 ,  ), … (
 ,  ))
where d	 means the i-th document, 
 expresses the j-th
keyword words of the i-th document, and  represents the
weight of the j-th keyword in the i-th document.
This paper adopts classical TF-IDF as the clustering
keywords weight calculation method because it has an advantage in considering words occurrence frequency not only
in a document but also in the whole date set. Furthermore, in
this paper the size of each document is also taken into account, and the parameter weight is defined by (2).

459

with a given threshold Ȝ. On one hand, if the similarity is
bigger, the data shall be put into a cluster with its similarity
biggest.On the other hand, the thought of mutation in the
genetic algorithm is used in here, the data should be added
into cluster center as a new one which can cause cluster center number change.
Step 3 Recalculate the center of each cluster which is defined as the arithmetic average value of all data in this cluster.
For example, it is assumed that there are 3 documents in the
first cluster, which are
 = (H, 2), (G, 3)
 = (H, 3), (G, 3)
J = ((H, 4), (G, 3), (L, 1))
Their new cluster center should be:

A. Document Presentation Based on Visual Features
As the most widely used document presentation method,
the mentioned model VSM represents document in two ways.
In one way we can segment words and select clustering
keywords according to words’ frequency by mainly analyzing the body of the document, or put clustering keywords
selected in the first time into selection from the whole document, and according to the clustering keywords’ position,
their weight shall be adjusted if they occurrences in title or
abstract. In the other way, only title and abstract are analyzed
to retrieve clustering keywords and do further clustering,
though effective, the result obtained in this way is not accurate enough.
In this paper, a document representation based on visual
features is defined with a full consideration of the importance of each visual feature in the whole document. Therefore, we segment words on the basis of every visual feature
independently and retrieve clustering keywords from each
part with features extraction method introduced above. And
according to the importance of every visual feature, it shall
be adjusted for the clustering keywords’ weight (< ) of
comprehensive document representation, with < be obtained by (4) and comprehensive document presentation
shown in (5).

-MN
M: = OH,

< =

>?@ AB@ CD@ 2E@ %F(@ )
>AC2%

J

 , G,

JJJ



J

J

 , L,

Q

= ((A, 3), (B, 3), (C, 0.33))
Step 4 Calculate the similarity for every pair of new cluster centers obtained in step 3. The thought of crossover in
genetic algorithm is used in here. Two clusters have to be
merged if the similarity between them is bigger than Ȝ. For
example, there are 2 cluster centers: center1= ((A, 3), (B, 4),
(C, 2)), center2= ((A, 2), (B, 4), (C, 3)), and the two merged
into one cluster center, that is,
-MN
M: = OH,



JP



J


 , G,

PP


 , L,

J


Q

= ((A, 2.5), (B, 4), (C, 2.5))
Step 5 Execute step 2, step 3 and step 4 once more, and
finish this process if cluster center reaches a stable value or
maximize iteration times, or else return to step 2 and continue to execute this process.

<
<
<
), (
 , 
), … , (
 , < ), … , (
 , 
< = (
 , 
)  

where G  means the weight of clustering keyword i in
body part, and the values of a, b, c, d, e must be either part
equal to 0 or all no less than 1. In our experiment we set the
values of a and b equal to 2, others equal to 1.

IV.

IMPLEMENTATION OF VF-CLUSTERING IN CHINESE
SCIENTIFIC DOCUMENT CLUSTERING

A. Evaluation of Clustering Results
There is still no uniform standard for the evaluation of
document clustering results, however, precision rate and
recall rate which reflect two different aspects of quality clustering must be taken into account together. Since F1 test
value combines the two precisely, we use the most commonly evaluation, precision rate, recall rate and F1 test value to
evaluate the effect of the document clustering.
Each artificial labeled theme Ti in data set corresponds to
a clustering result set L in clustering result. Now we define
recall rate, precision rate and F1 as follows:

B. K-means Algorithm Optimization Based on Crossover
and Mutation
Take advantage of the idea of crossover and mutation in
genetic algorithm during the process of clustering, this algorithm dynamically adjusts the values of k as well as cluster
center by means of mergence and addition, to achieve kmeans algorithm optimization.
Optimized clustering algorithm process is as follows:
Input: The initial number of cluster center k, Similarity
WKUHVKROGȜ In our experiment we set the value of k equal to
4.
Output: The clustering clusters formed finally (the number of clusters not necessarily equals k).
Step 1 Initialize cluster centers. First of all, it is necessary to check whether the newly selected cluster center is the
existed one. If it is, the cluster center can be reproduced. Or
else calculate the similarity between the current centers and
VHOHFWHGRQHDQGFRPSDUHWKLVVLPLODULW\ZLWKȜ,IWKHVLPilarity is bigger, reselect a document as a new center and go
back to execute step 1 once more until the number of cluster
center equal to k.
Step 2 Calculate the similarity between each data and
each cluster center, and then compare the biggest similarity

RS , L  =
WS , L  =
X1 =

460

TF UV T
F
TF UV T
V

YF ,V Z(F ,V )
YF ,V Z(F ,V )

(6)
(7)
(8)

netic Algorithm (GA). We pre-treatment the data set, we
separately extract five visual features of each document to a
save to the database table. The part of the experimental original data is shown in Fig. 1.

B. Experiment and Result Analysis
Text data sets are from 195 articles of Chinese scientific
and technical document in CNKI, including 47 articles of
Clustering Algorithm (CA), 58 articles of Data Mining (DM)
43 articles of Cloud Computing (CC) and 47 articles of Ge-

Figure 1. The part of the experiment original data

where the label is artificial classified marks, while nl shows
the clustering result.
The first step of the experiment: firstly, make word segment for five visual features independently, remove stop
words and extract clustering keywords; then, make a clustering for each visual feature that represents documents independently. The experimental result is shown in TABLE I.
Where the k-means shows the basic clustering algorithm and
make the body representing the documents, all others adopt
the improved algorithm.

same results when make the body representing document
independently. But the clustering running time are reduced
when use the improved algorithm.
2) The clustering performance by visual features body
and subtitle are best in representing documents independently, and good steady is exhibited in these types of data sets.
What’s more, the visual feature body has slightly better clustering results than subtitle.
3) The visual feature keyword is better than abstract and
title in clustering effect, moreover, abstract and title are poor
in the stability of the clustering result by representing document independently. Among these three visual features, clustering has a good effect in a new subject or a subject with
fewer applications. However, it has a relatively poor effect in
subject with extensive applications.
4) The visual features title has poor clustering results in
subject with extensive applications.
Under the first step of the experimental results, we make
an analysis of clustering results obtained through different
visual features representing the document independently. We
make different combinations of visual features to represent
the document and clustering. The result is shown in TABLE
II.
Summarize the analysis of the results of the second step
of experiment as follows:
1) From the whole analysis of the two results in TABLE I
and TABLE II, it’s obviously draw that the clustering result
of the comprehensive visual features is better than any single
visual feature in representing documents.

TABLE I. RESULTS OF CLUSTERING BY FIVE VISUAL FEATURES

CA

DM

CC

GA

R
P
F1
R
P
F1
R
P
F1
R
P
F1

k-means(%)

B (%)

A (%)

S (%)

K (%)

T (%)

76.60
83.72
80.00
93.10
90.00
91.53
93.02
90.69
91.84
93.62
84.62
88.89

76.60
83.72
80.00
93.10
90.00
91.53
93.02
90.69
91.84
93.62
84.62
88.89

74.47
53.03
61.95
91.38
82.81
86.89
90.69
88.38
89.50
40.43
95.00
56.72

76.60
85.71
80.90
93.10
88.52
90.76
90.70
86.04
88.30
89.36
86.27
87.79

55.32
92.86
69.33
86.25
84.85
85.54
95.35
97.62
96.47
100.00
79.66
88.68

53.19
48.93
50.97
87.93
82.26
85.00
93.02
78.43
85.11
91.79
58.11
71.07

Through the analysis of the first step of the experimental
results, we could conclude as follows:
1) Because the value of the k is equal to 4, so the basic
algorithm and the improved algorithm to clustering have the

461

TABLE II. RESULTS OF CLUSTERING BY DIFFERENT COMBINATION

and heightens the efficiency greatly by adjusting the values
of k and cluster center dynamically in the process of clustering.

S, K (%) B, S (%) B, S, K (%) B, S, K, A (%) B, S, A, K, T (%)
CA

DM

CC

GA

R
P
F1
R
P
F1
R
P
F1
R
P
F1

80.85
90.48
85.39
94.83
96.49
95.65
97.67
97.67
97.67
95.74
84.91
90.00

85.11
93.02
88.89
98.28
90.48
94.21
100.00
100.00
100.00
93.62
95.65
94.62

95.74
91.84
93.75
93.10
100.00
96.43
100.00
100.00
100.00
100.00
95.92
97.92

95.74
90.00
92.78
93.10
96.43
94.74
97.67
100.00
98.82
95.74
95.74
95.74

95.74
93.75
94.74
94.83
98.21
96.49
97.67
100.00
98.82
100.00
95.92
97.92

ACKNOWLEDGMENT
This work is supported by Shanghai Leading Academic
Discipline Project (J50103) and Innovation Program of
Shanghai Municipal Education Commission (11ZZ85).
REFERENCES
[1]

[2]

2) Although the clustering results of visual features that
consist of subtitle and keyword are slightly better than the
visual feature body representing documents independently,
the effective number of characters of subtitle and keyword is
less than the body’s, so it greatly enhances the efficiency of
feature words selection when making words segment. This
way could be used to meet the high requirements of the clustering results and efficiency.
3) The integrated independent visual feature includes
body, subtitle and keyword, in which each one has the best
clustering results to express text, and its clustering results is
almost the same as the one that integrate five visual features
to represent a document. Moreover, the clustering results of
these two combinations are the best, although the efficiency
is not so good. In order to meet the higher requirement of the
clustering results, we could combine body, subtitle and keyword together to represent a document.
V.

[3]

[4]

[5]

[6]

[7]

[8]

CONCLUSION

[9]

This paper implements a method to cluster the scientific
documents based on visual features (VF-Clustering). And
through the deep analysis of these clustering results we find
some useful information as follows:
1) In the five visual features, body representing documents independently to cluster have the best accuracy and
steadiness, and subtitle is next. However, the clustering effect of abstract, keyword and title are not very good, especially in the widely applied field of knowledge clustering.
2) The accuracy of clustering by combining subtitle and
keyword is better than each of them individually. Moreover,
operation time can be saved greatly for the less effective
characters in the two parts. If the efficiency is an essential
factor, clustering by combining subtitle and keyword can be
an optimal choice.
3) If the higher accuracy is demanded, clustering combining body, subtitle and keyword is a better choice.
This paper also uses the thought of crossover and mutation in genetic algorithm to improve the k-means algorithm

[10]
[11]

[12]

[13]

[14]
[15]
[16]

462

S. Guha, R. Rastogi, and K. Shim, “An efficient clustering algorithm
for large databases,” ACM SIGMOD international conference on
Management of data, Volume 27 Issue 2, June 1998.
A. Likasa, and N. Vlassisb, “Verbeekb. The global k-means
clustering algorithm. Pattern Recognition,” 2003, pp. 451 – 461.
J. A. Hartigan, and M. A. Wong, “A K-Means Clustering Algorithm,”
Journal of the Royal Statistical Society, Series C (Applied Statistics),
Vol. 28, No. 1,1979, pp.100-108.
K. Wagsta, C. Cardie, S. Rogers, and S. Schroedl, “Constrained Kmeans Clustering with Background Knowledge,” Proceedings of the
Eighteenth International Conference on Machine Learning, 2001, pp.
577-584.
R. Dutta, I. Ghosh, A. Kundu, and D. Mukhopadhyay, “An Advanced
Partitioning Approach of Web Page Clustering utilizing Content &
Link Structure,” Journal of Convergence Information Technology
Volume 4, Number 3, 2009.
J. L. Neto, A. D. Santos, and C. A. A. Kaestner, “Alex A. Freitas,
Document Clustering and Text Summarization,” Information
Processing and Management, 2000.
J.M. Pena , J.A. Lozano, and P. Larranaga, “An empirical comparison
of four initialization methods for the K-Means algorithm,” Pattern
Recognition Letters, 1999, pp.1027-1040.
L. Yanjun, M. Chung , and D. Holt, “Text document clustering based
on frequent word meaning sequences,” Data & Knowledge
Engineering, 2008, pp. 381–404.
E Rasmussen, P. Hall, and E. Cliffs, “Clustering algorithms,”
Information Retrieval, 1992, pp.419-442.
A. K. Jain, and M. N. Murty, “Data Clustering: A Review,” ACM
Computing Surveys (CSUR), 1999, pp.264–323.
W. B. Cavnar, “Using An N-Gram-Based Document Representation
With A Vector Processing Retrieval Model,” Proc. of TREC-3 (Third
Text REtrieval Conference), Gaithersburg, 1994.
G. Salton, and C. Buckley, “Term-weighting approaches in automatic
text retrieval,” Information Processing and Management 24, 513-523.
1988. Reprinted in: Sparck Jones, K. and Willet, P. Eds. Readings in
Information Retrieval, 1997, pp.323-328.
N. Grira, Crucianu, and M. Boujemaa, “Unsupervised and semisupervised clustering: a brief survey,” 7th ACM SIGMM
international workshop on Multimedia information retrieval, 2005,
pp.9-16.
U. Maulik, and S. Bandyopadhyay, “Genetic algorithm-based
clustering technique, Pattern Recognition,” 2000, pp.1455-1465.
K. Krishna, and M. Narasimha Murty, “Genetic K-Means Algorithm,
Item Identi¿HU6” 1999, pp.1083-4419.
J. F. Navarro, C. S. Frenk, and S. D. M. White, “A universal density
profile from hierarchical clustering,” The astrophysical jouranl, 1997,
pp.490-493.

