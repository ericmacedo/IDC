Landscape Ecology 16: 471–490, 2001.
© 2001 Kluwer Academic Publishers. Printed in the Netherlands.

471

Research Article

A multiscale framework for landscape analysis: Object-specific analysis
and upscaling
G.J. Hay1,∗ , D.J. Marceau1 , P. Dubé1 and A. Bouchard2
1 Geocomputing

Laboratory, Départment de géographie, Université de Montréal, C.P. 6128, succursale
Centre-Ville, Montréal, Qué, Canada, H3C 3J7; 2 IRBV, Université de Montréal, Jardin Botanique de Montréal,
4101 Sherbrooke Est, Montréal, Qué, Canada. H1X2B2; ∗ Author for correspondence (Tel: (514) 343-8073; Fax:
(514) 343-8008; E-mail: ghay@sympatico.ca)
Received 15 October 1999; Revised 10 April 2001; Accepted 5 April 2001

Key words: domains of scale, image-objects, landscape thresholds, MAUP, multiscale, object-specific analysis,
OSA, OSU, remote sensing, scale, upscaling

Abstract
Landscapes are complex systems that require a multiscale approach to fully understand, manage, and predict
their behavior. Remote sensing technologies represent the primary data source for landscape analysis, but suffer
from the modifiable areal unit problem (MAUP). To reduce the effects of MAUP when using remote sensing data
for multiscale analysis we present a novel analytical and upscaling framework based on the spatial influence of
the dominant objects composing a scene. By considering landscapes as hierarchical in nature, we theorize how
a multiscale extension of this object-specific framework may assist in automatically defining critical landscape
thresholds, domains of scale, ecotone boundaries, and the grain and extent at which scale-dependent ecological
models could be developed and applied through scale.

Introduction
To better understand, manage, and predict the behavior of the complex systems that provide life on
earth, we require an improved understanding of the
scale-specific interactions responsible for landscape
metabolism (Levin 1992), robust techniques for visualizing and deciphering multiscale processes from
patterns (Turner et al. 1991), and appropriate scaling
strategies for linking and modelling data at multiple scales (King 1990; Ehleringer and Field 1993).
To assist landscape ecologists in these tasks modern
remote sensing technologies provide multi-resolution
data sources for analysis and hypothesis testing over
both large and small areas, and hierarchy theory provides a useful analytical framework for describing the
landscape’s composition within these scenes.
According to hierarchy theory, ecological systems are considered as ‘nearly decomposable’ hierarchically organized entities resulting from (different)

structuring processes exerting their influence over defined ranges or domains of scale (Allen and Starr
1982; O’Neill et al. 1986; Holling 1992). Conceptually, the decomposability of these systems implies
that their analysis and understanding can be enhanced
by organizing their numerous components into fewer
discrete, interactive units at different levels based on
differences in process rates (O’Neill et al. 1989; King
1999). When these ideas are considered in relation to
the spatial, spectral, temporal, and radiometric properties inherent to remote sensing data (Marceau and
Hay 1999a), the keys to fully unlock the complex relationships between scale-specific landscape patterns
and processes appear close at hand. For example,
Moody and Woodcock (1995), Benson and MacKenzie (1995), O’Neill et al. (1996), and Pax-Lenney
and Woodcock (1997) describe the influence of remote
sensing resolution on detecting landscape patterns and
processes. Bian and Walsh (1993), Souriau (1994)
and Walsh et al. (1997) discuss the identification of

472
Table 1. List of general terms and abbreviations.
AVHRR
AVIRIS
C.Cut
CASI
CCD
DNs
FPAR
HPDP
H-res
IFOV
LAI
L-res
MAUP
MODIS
PSF
RMSE
SPOT
TM

Advanced very high resolution radiometer
Airborne Visible Infra-Red Imaging Spectrometer
Clear-cut
Compact Airborne Spectrographic Imager
Charged-couple device
Digital numbers or gray-scale values
Fraction of photosynthetically active radiation
Hierarchical Patch Dynamics Paradigm
High resolution
Instantaneous field of view
Leaf area index
Low resolution
Modifiable areal unit problem
Moderate-resolution Imaging Spectroradiometer
Point-spread function
Root mean square error
Satellite pour l’Observation de la Terre
Landsat Thematic Mapper

landscape scale-thresholds and domains of scale as
viewed in remotely sensed data. Caldwell et al. (1993),
Ustin et al. (1993), Friedl et al. (1995), Cullinan et al.
(1997), DeFries et al. (1997), and Stewart et al. (1998)
describe the challenges of scaling remote sensing data
and the implementation of multiscale approaches for
ecosystem models.
In addition to the remote sensing platforms more
familiar to landscape ecologists such as AVHRR⊗ ,
TM⊗ and SPOT⊗ , lesser-known hyperspectral airborne sensors like CASI⊗ and AVIRIS⊗ have been in
operation for over a decade providing unique opportunities to diagnostically examine landscape patterns
and processes at very fine spatial and spectral scales
(Wessman et al. 1989). These sensors allow for the
discrimination of landscape structures that are absent
in coarser imagery, thus providing opportunities to
link field data with patterns at much coarser scales
(Treitz and Howarth 2000). They also serve as excellent test-beds for conducting fine-scale landscape
analysis in preparation for data available from the
new high-resolution satellites such as Ikonos (with its
commercially available 1 m2 panchromatic and 4 m2
multispectral channels), MODIS⊗ (with its 36 coregistered channels ranging from 250 m2 –1 km2 ), and
Hyperion (launched in November, 2000 with a capac⊗ See Table 1.

ity to acquire 220 spectral bands (from 0.4 to 2.5 µm)
at a 30 m2 spatial resolution).
It is becoming increasingly apparent that in order
to fully understand the complexity of landscape dynamics we require the ability to recognize broad-scale
patterns and processes, and relate them to those at finer
scales where we are most familiar (Wu and Qi 2000).
These high-resolution sensors provide critical data and
perspectives that will assist in bridging this knowledge
gap.
While remote sensing data hold great promise, it is
also important to recognize their limitations. In particular, all remote sensing data represent a unique form
of the modifiable unit areal problem or the MAUP (for
a comprehensive review see Marceau 1999). Though
the importance of MAUP has previously been noted
in landscape ecology (Jelinski and Wu 1996), its relationship to remote sensing data remains poorly recognized and understood (Wu et al. 2000). In particular,
the effects of MAUP can be especially devastating
during scaling, where arbitrarily extrapolating sitespecific measurements to coarser scales can result in
substantial error (Gardner et al. 1982; King 1990).
Thus the ramifications for inappropriately using remote sensing data to understand multiscale landscape
patterns/processes are profound. This is especially relevant in landscape ecology, where multiscale studies
are increasingly conducted (Wu and Qi 2000), and
where land-cover classifications generated from satellite imagery are frequently used to characterize the
ecology of large areas and to make generalizations
about the distribution of species and communities
(Townsend 2000).
The primary objectives of this paper are to describe a novel approach for analyzing and upscaling
remotely sensed data, and a multiscale extension to
this approach, both of which are based on the spatial influence of the dominant objects composing the
scene, rather than relying solely on user bias. These
novel approaches incorporate object-specific analysis
and solutions to the MAUP. Together they represent
a framework for spatially defining critical landscape
thresholds and domains of scale, ecotone boundaries,
and the grain and extent at which scale-dependent
ecological models could be developed, and applied.
Theoretical background
The following two sections briefly provide a theoretical background on scale, scaling, the relationship
between remote sensing imagery and MAUP, and the

473
fundamentals of object-specific analysis and objectspecific upscaling, and their relationship with other
scaling techniques.
Scale, scaling, remote sensing imagery and MAUP
Conceptually, scale represents the ‘window of perception’, the filter, or measuring tool with which a system
is viewed and quantified. As scale changes, so do the
associated patterns of reality, which has obvious implications for understanding any organism, place, or
system. An important characteristic of scale lies in
the distinction between grain and extent. Grain refers
to the smallest intervals in an observation set, while
extent refers to the range over which observations at
a particular grain are made (O’Neill and King 1998).
Within a remote sensing context, grain is equivalent
to the spatial resolution of the pixels composing an
image, while extent represents the total area that an
image covers.
Associated with multiscale analysis is the term
domain of scale (or scale domain). This refers to a
region of the scale spectrum over which, for a particular phenomenon, patterns do not change or change
monotonically with changes in scale. Such domains
are separated by scale thresholds - relatively sharp
transitions or critical points along the spatial scale
continuum where a shift in the relative importance of
variables influencing a process occur (Meentemeyer
1989; Wiens 1989).
To analyze objects, or entire scenes at different scales, and to utilize information between these
scales, appropriate scaling methods are required. Scaling refers to transferring data or information from
one scale to another. It requires the identification of
the factors operational at a given scale of observation, their congruency with those on the lower and
higher scales, and the constraints and feedbacks on
those factors (Caldwell et al. 1993). As noted by Jarvis
(1995), scaling represents a real challenge because of
the non-linearity between processes and variables, and
heterogeneity in properties that determines the rates
of processes. In practice, scaling can be performed
from a ‘bottom-up’ or a ‘top-down’ approach: upscaling consists of using information at smaller scales to
derive information at larger scales, while downscaling
consists of decomposing information at one scale into
its constituents at smaller scales.
Allen and Hoekstra (1991) suggest that scale is not
a property of nature alone but rather is something associated with observation and analysis, and that the

scale of a process is fixed only once the observer has
specified the actors in the system. So what happens
when the scale of observation is arbitrarily derived, as
is the case with remote sensing data? Quantification
problems resulting from such arbitrariness are known
as the modifiable unit areal problem or the MAUP
(Openshaw and Taylor 1979; Openshaw 1981).
The MAUP originates from the fact that a significant number of different – often arbitrary – ways
exist by which a study area can be divided into nonoverlapping areal units for the purpose of spatial
analysis. In essence, the MAUP represents the sensitivity of analytical results to the definition of data
collection units, and is illustrated by two related but
distinct components: the scale problem and the aggregation problem. The former is the variation in results
that can be obtained when areal units are progressively aggregated into fewer, larger units for analysis;
the latter represents the variation in results generated by the use of alternative aggregation schemes at
equal or similar resolutions (Openshaw 1984). Consequently, the potential for error in the analysis of
spatial data resulting from MAUP is significant, and
has been recognized in a number of studies (Dudley
1991; Fotheringham and Wong 1991; Hunt and Boots
1996).
Marceau (1992) was among the first to demonstrate that remote sensing data represent a particular
case of the MAUP. In a remote sensing scene, an image
may be envisioned as a regular net arbitrarily thrown
over a study area where the grain and extent of the
mesh define the areal units measured (Figure 1). More
correctly, each pixel represents an integrated radiance
measure corresponding to the spectral, spatial, temporal, and radiometric influence of the real-world objects
within the area delineated by the instantaneous field
of view (IFOV) of the sensor (Duggin and Robinove
1990). IFOV determines how much of the ground area
the sensor ‘sees’ at any given instant in time. This results in three general situations: the ground features
of interest are smaller than, approximately equal to, or
larger than the spatial sampling unit. It should be noted
that within a single image, each of these sampling
combinations are possible, and in fact very probable.
In the first situation, this type of image is referred to as
low resolution or L-res, in the second and third cases,
as high resolution or H-res (Woodcock and Strahler
1987). Consequently, every image is characterized by
a scale and aggregation level, which determines its
structure and information content. Recognizing this is
critical for determining what information can be ex-

474

Figure 1. The relationship between grain and extent in remote sensing imagery.

tracted from an image, and how reliable it is (Marceau
et al. 1994).
Fortunately, several solutions to MAUP have been
suggested (Fotheringham 1989). In particular we note
two important concepts related to these solutions.
First, the MAUP does not exist if analysis is performed
with basic entities. The term basic entity refers to an
object composed of similar parts that are different than
itself. For example, if we consider a tree-crown as a
basic entity, conceptually it may be composed of, or
is an aggregate of leaves, and branches, each of which
individually belongs to classes that are themselves, basic entities. Thus, identifying basic entities provides
the clearest way out of the MAUP, as a user works with
spatially discrete entities rather than arbitrarily defined
areal units (for additional information see Fotheringham, 1989). Second, while the MAUP certainly poses
significant challenges, it can also reveal critical information for understanding the structure, function,
and dynamics of complex real world systems if it is
recognized and dealt with explicitly (Jelinski and Wu
1996). Part of the challenge in recognizing MAUP is

that there is no unique ‘MAUP statistic’ to quantify its
influence, though correlation analysis and other techniques have been used (Amrhein and Reynolds 1996;
Hunt and Boots 1996). Instead, users of spatial data
must be cognizant of the fact that spatial analysis of
arbitrarily defined areal units can produce results that
may not necessarily represent the content of the original units, but rather, the associations between them
(i.e., aggregation problem) and the scale at which they
were assessed (i.e., scale problem).
The fundamentals of Object-Specific Analysis (OSA)
and Upscaling (OSU)
Object-Specific Analysis (OSA) is a multiscale technique that defines unique spatial measures, specific
to the individual objects composing a remote sensing scene. These object-specific measures are then
used in weighting functions for upscaling an image to
a coarser resolution. The resolution of the upscaled
image can either be defined manually by the user
(see further), or automatically by statistical properties of the objects composing the image (see further).

475

Figure 2. Tree-crown image-objects. This CASI sub-image has
been magnified to illustrate the relationship between individual
pixels (gray-tone squares) and the tree-crown image-objects they
perceptually represent. Individual crown centers are defined by a
single black pixel. The spatial resolution of each pixel is 1.5 m2 .

Both forms of upscaling are referred to as ObjectSpecific Upscaling (OSU) because they incorporate
object-specific weights. Thus, MAUP effects are minimized in both OSA and OSU, as object-specific spatial
information is incorporated throughout the analysis.
An underlying premise of OSU is that H-res
image-objects should have more influence on an upscaled signal than a single L-res pixel – which signal is
already regularized1 . The term ‘image-objects’ refers
to basic entities, located within an image that are perceptually generated from H-res pixel groups, where
each pixel group is composed of similar digital values,
and possesses an intrinsic size, shape, and geographic
relationship with the real-world scene component it
models [e.g., a tree crown (Figure 2)].
The heuristics determining this threshold of ‘similarity’ are based on the novel concept that all pixels
within an image are explicitly considered H-res samples of the scene-objects they model, even though (as
previously described) each pixel many represent both
H- and L-res object information. The importance of
this rule is that by biasing for H-res samples only,
we explicitly seek objects that exist at, or over, a
larger spatial extent than the area covered by the individual pixels that compose them. Essentially, we
are using parts of objects (grain) to define the extent of objects that exist at their next (coarser) scales.
1 Regularization is a signal-processing term describing the integra-

tion of signals generated by objects that are no longer individually
discernable (thus L-res), due to the physical limitations of the
sensing device in relation to the size of the objects being assessed.

The spatial extents defined are then used as weights
to representatively upscale the image to a coarser
resolution.
Similar to Mandelbrot’s famous question concerning the length of a coastline, the answer is dependent
on the precision of the measuring tool (Mandelbrot
1967). In the case of OSA, the maximum sized object
that can be defined is represented by the relationship
between the spatial resolution of pixels composing the
objects within a scene, and the ability of the heuristics
to define this object’s edges. As a result, this technique can be applied to any type of remote sensing
data from H-res data such as the CASI (airborne), and
Ikonos (satellite), to medium resolution TM and lowresolution AVHRR. The only difference in each case
is to appreciate the relationship between the pixel size,
and the geographic size of the object of which the pixel
is a component. In a CASI data set, pixels could be
considered parts of individual trees, trees being the
object of analysis. In TM data, individual pixels may
be considered parts of a particular forest stand, and in
AVHRR data, individual pixels may represent parts of
a larger extent, more general landscape entity such as
a deciduous broad-leaf forest class.
Though sharing similarities with other scaling and
scale detecting techniques (Turner et al. 1991; Gardner 1998), OSA is unique, in that it incorporates an
explicit multi-resolution (i.e., hierarchical) sampling
and evaluation of each pixel in relation to the (different sized) coarser grain objects of which it is a nested
constituent. For example, while scale variance analysis (Moellering and Tobler 1972) is also a hierarchical
approach, there is no consideration of pixels as parts of
individual objects composing a scene. Instead, pixels
composing the image are aggregated by systematically
increasing grain size (for the entire image), resulting
in a nested hierarchy of images with the same extent,
but with different spatial resolutions. A measure of the
total scene variance is then evaluated for each image
in the hierarchy, and the results are plotted illustrating
potential scale thresholds at specific resolutions within
the entire scene. A similar approach is described by
Woodcock and Strahler (1987), where local scene variance is graphed as a function of increasing spatial
resolution, and also by Marceau et al. (1994) where
a minimum spectral variance threshold is used to define the optimal spatial resolution of different forest
classes.
In OSA, a ubiquitous ‘optimal’ resolution is never
found, as none exists in images representing complex heterogeneous environments (Hay et al. 1997).

476
Instead, different ‘optimal’ resolutions or thresholds
are defined based on the different objects being assessed (Hay et al. 1996). In the previous examples,
the described techniques are used for scale exploration
only. They do not explicitly consider individual pixels
as parts of variously sized, shaped, and spatially distributed objects, and they do not include facility for
upscaling, or provide information indicating where in
the image such spatial thresholds exist. OSA does not
share these limitations.
Materials and methods
Study site
Our initial interest in scale issues was based on understanding the spatial evolution of individual trees and
forest gaps through scale (Marceau and Hay 1999b),
particularly as it relates to changes in landscape fragmentation. To facilitate this we applied OSA and
OSU to H-res CASI data, which allowed us to follow
the evolution of familiar image/site structures through
scale. The CASI (Compact Airborne Spectrographic
Imager) is a pushbroom sensor designed to operate
from light aircraft and helicopters, with data capture
capabilities based on a two-dimensional frame transfer
CCD array. 16 bit signed data were collected during 20:10–21:40 h (GMT) over the Sooke Watershed,
Vancouver Island, British Columbia, Canada on August 1, 1993 (Figure 3). The data were radiometrically
corrected to 1.5 m2 pixels, and a study site (Figure 4a) was located along Rithet Creek and extracted
from a channel centered at 0.66 µm (+/− 0.05 µm).
This scene was then corrected for geometry and
atmosphere, and all subsequent analyses were performed on it. Ancillary data include 1:10,000 forest
inventory maps, numerous field surveys, and 1:12,000
color near-infrared (NIR) aerial photography (1993).
In this area, the very dry maritime Coastal Western
Hemlock biogeoclimatic subzone dominates, though a
small component of moist maritime Coastal DouglasFir subzone also exists.
In Figure 4a, three principal stand types are visible, each of which illustrates the dominant seral
tree species - Coastal Douglas-Fir [(Pseudotsuga menziesii) (Mirb.) Franco var. menziesii]. Located in the
center of this image is a mature stand (141–250 yrs)
with a crown-closure of 56–65%. Below it (bottom
center) is a dense young stand (21–30 yrs) with a
crown-closure of 76–85%. Surrounding these two, notably on the image left, is a stand of mixed-immature

and mixed-young individuals (1–20 yrs), with crown
closures ranging from 0–45%. Three gravel roads
transect the scene and are represented as bright linear features. An exposed sparsely vegetated clear-cut
(C.Cut) lies adjacent to a gravel road at the upper right
quadrant of the scene, and a small, partially vegetated
marsh is located at the bottom right. Throughout the
site, many exposed soil, and soil-grass patches are visible. In the Thematic Map (Figure 4b), these patches
have been classified as C.Cut.
OSA and user-defined OSU
In the earth sciences it is generally observed that objects closer to each other are more alike than those
further apart (Curran and Atkinson 1998). Similarly,
in a remotely sensed image, spatially near pixels tend
to elicit a strong degree of spectral autocorrelation.
Therefore, plotting the digital variance of samples
(pixels) located within increasingly larger kernels,
while centered on an image-object of known size tends
to produce a distinct break, or threshold in variance
as increasing sized kernels contact the image-object’s
edges. The unique window size (VTw ) defined at
this variance threshold location (VTij) corresponds
explicitly to the object’s known size, and is a key
component for determining object-specific weighting
values [i and j represent row and column within the
original CASI image (OI )]. Conceptually, VTw may
be considered similar to lag as described when using
semivariance. For example, the window size at location (A) in Figure 5 represents the maximum scale
for defining the (inset) tree-crown2 . Locations B-C,
D-E, and F-G, represent an object-specific range of
‘optimal’ window sizes for defining the nested imageobjects, of which the center tree-crown pixel (white
dot) is a member. Locations B, D, and F represent
the local variance minima corresponding to the scales
where the next set of ‘nested’ objects are first manifest.
Minimum variance indicates that the pixels composing
this measure are locally the most spectrally similar,
thus they are the most ‘object-like’, while variance
maxima located at C, E, and G, respectively, represent
the maximum spatial extents of these nested objects.
Locations A-B, C-D, and E-F are explained in the
Discussion section.
The window size at one iteration prior to VTij is
used to define the maximum area (Aij ) at which the
2 The inset image has been extracted form the mature-stand in O ,
I
and the corresponding curve represents the actual variance values
determined at each incremented widow size.

477

Figure 3. Rithet Creek study site map.

Figure 4. Remote sensing image and thematic map of the study site. A). CASI image illustrating the study area (36 ha2 ) at a spatial resolution
of 1.5 m2 . B). Thematic site map and legend (same scale).

478

Figure 5. Variance characteristics of a single tree-crown pixel defined through multiple scales. The curve of this graph results from plotting
the variance of the digital values of all pixels located within increasing sized square windows. In this illustration, varying sized windows are
centered over an individual tree-crown (circular image-object) that is located within the white bars of the inset image. The crown center is
defined by a single white pixel that represents the apex of the tree. As the window size increases, the resulting variance value is plotted. In
practice this form of multiscale analysis is applied to all pixels composing a scene. The maximum window size specified for each pixel is defined
when variance measures meet unique object-specific heuristics that correspond to the spatial extent of the real-world objects they model.

central pixel under analysis is spectrally and spatially
related to its neighbours. At the same time that Aij is
defined, the corresponding mean (Mij ) and variance
(Vij) values are also defined for the central pixel within
VTw . These procedures are then applied to all remaining pixels in OI , resulting in corresponding variance
(VI ), area (AI ), and mean (MI ) images.
Once VI , AI , and MI have been generated, two
steps are required to complete user-defined OSU. The
first involves determining an object-specific weight
(Wij ) for each (∀) pixel (Pij ) in OI , which is represented by WijK .
∀Pij ∈ OI

(1)

WijK = (AijK /SK )
WijK defines the object-specific weight for each Aij
within an upscaling kernel (K) [of a (k ∗ k) user-defined
dimension], where SK is the sum of all Aij within K
(see equation 2).
SK =

k
k 

i

Aij

(2)

j

The second step is to apply the object-specific weight
to produce a new upscaled image.

∀UPLM ∈ UI

 k k


∗
Oij Wij
UPLM =
L

(3)

M

UPLM represents an upscaled pixel located at row L,
column M, in the resultant upscaled image UI . Oij
is the DN (digital number) of the pixel located in
the original image at row i, column j , that is evaluated within the upscaled kernel. UPLM and the pixels
within rows (i − k, j + k) and columns (i + k, j − k)
represent the same real-world extent. Thus UI is composed of fewer pixels than OI , though both represent
the same geographic area. Resampling within the upscaling kernel is represented by the double summation
of all DNs to a single object-weighted pixel value
that is located within the new upscaled image. The
non-overlapping kernel is then moved a distance of K
pixels across OI , and the process is iterated until a new
upscaled image UI is generated.
A multiscale extension: Iterative OSA and OSU
Although a single remote sensing scene represents a
unique instance of all discernible objects within its
extent, we hypothesize that it also contains additional
information related to image-objects (IOs) that exist

479
over a ‘limited’ range of coarser, non-immediately discernible spatial scales, located within the same extent.
Support for this comes from three sources:
1. Appreciating that both H- and L-res information
exists within an image collected at a single resolution (Woodcock and Strahler 1987)
2. Understanding the intimate relationship between
IFOV and object size (Slater 1980)
3. Recognizing that previous work illustrates the ability of OSU methods to reveal patterns that consistently model the spatial extent of differently sized
objects existing at coarser scales (i.e., tree crowns,
canopy gaps, etc, Hay et al. 1997).
To exploit this range of multiscale information
within a single image, we hypothesize that by iteratively applying OSA to define object-specific (maximum and minimum) variance-thresholds within MI ,
dominant landscape objects will emerge through the iteration process. In essence we are applying principles
of non-linear feedback to ascertain if self-organization
(Kay and Schneider 1995) – in the form of patterns
corresponding to the spatial extent of dominant landscape objects – will ‘emerge’ at each new scale. We
note that our goal in developing and applying objectspecific techniques is to allow for previously existing
self-organized patterns (i.e., image-objects) to be detected within the image/landscape at different scales.
It is not to generate new self-organizing patterns. This
subtle difference is important to clarify, because a
strict requirement of self-organization includes temporal evolution (Nicolis and Prigogine 1989; Coveney
and Highfield 1991), while a single remote sensing
image – and all analysis performed on it – can only
represent an instance in time.
The result of this iterative approach is a nested hierarchy of image-sets (ISt ) composed of VI , AI and
MI that have membership (∈) in a unique scale domain (SDn ). Within this SDn , each image has the
same grain and extent, and represents the results of
multiscale analysis specific to the individual imageobjects composing it. Following this logic, each SDn is
a member of a scale-domain super set (SDS) that represents the entire range of object-specific multiscale
analysis (OSA) and scaling results (OSU) evaluated
within the fixed spatial extent of a unique digital landscape (OI ). This hierarchical structure (outlined in
Figure 6) may be described in the following manner:
Pij ∈ IOs ∈ ISt ∈ SDn ∈ SDS

(4)

Figure 6. Hierarchically nested components of iterative object-specific analysis (OSA) and object-specific upscaling (OSU).

A digital landscape is composed of pixels (Pij )
that are parts of image-objects (IOs ), that are defined
within a specific image-set (ISt ), that is a member of a
scale-domain (SDn ), which populates a scale-domain
set (SDS).
To operationalize this framework with minimal
user-bias, we apply object-specific concepts to select the most appropriate images for upscaling. To
minimize the scale problem resulting from arbitrary
scaling, we apply a resampling heuristic (Rh ) based
on the relationship between image-objects and pixel
size, and apply OSU as our upscaling algorithm (Hay
et al. 1997). This combination of iterative OSA and
OSU constitutes an object-specific multiscale framework for landscape analysis that is further discussed
in the following sections.
Selecting an iterated MI to upscale
Through the iteration process, MI pixels increasingly
become parts of objects existing over larger and larger
extents, yet the spatial resolution of the pixels representing each new image-object remains constant. To
reduce unnecessary computation, an appropriate MI
must be evaluated within each ISt to determine if upscaling is necessary. In the first OSA iteration, the
exact process described in section ‘OSA and userdefined OSU’ is applied. That is, each Pij is assessed

480
within larger windows until a local maximum variance
threshold (VTw(max) ) is reached that corresponds to a
‘peak’ location as illustrated by (A) in Figure 5. When
applied to the entire image, this process generates the
first image-set (i.e., V1 , A1 , M1 ).
In the second iteration, each Pij (in the newly
generated M1 ) is assessed within larger windows until a local minimum variance threshold (VTw(min) ) is
reached. This results in the generation of a second
image-set (i.e., V2 , A2 , M2 ) that represents the beginning scales of all newly emergent image-objects.
Conceptually, each pixel in M2 will be represented
by a local variance saddle or pit, as illustrated by (B)
in Figure 5. Therefore, odd-numbered OSA iterations
define scales representing the ‘end’ of objects, while
even-numbered OSA iterations define the beginning
scale of the next emergent object(s). As a result, all MI
generated from even-numbered OSA iterations will be
selected for upscaling.
Defining an upscale resolution (Rh )
Once an appropriate image has been selected for scaling, the upscale resolution will be defined by a resampling heuristic (Rh ) that is based on the relationship
between pixel size, and the size of the minimum discernible image-object for which VTw was initially developed. Rh is similar to recommendations by O’Neill
et al. (1996), who suggest a grain size 2 to 5 times
smaller than the spatial features of interest, and a
sample area 2 to 5 times larger than the patches assessed. We note that this grain size recommendation
corresponds to a reference by Slater (1980) regarding
the point-spread function (PSF)3 of the sensor. Essentially, if an object is less than 14 the size of the sensor’s
IFOV, its influence in the corresponding pixel is equal
to the sensor PSF. In modern sensors this value is exceptionally small, though it can be defined for each
sensor, and included within the model. For the purpose of this study, Rh equals the resampling resolution
where the minimum area (Amin ) of all pixels composing the image-objects defined in AI must be four times
larger than the spatial resolution of the current image.
This ensures not only detection (as implied by the 14
PSF rule), but also identification (Jensen 1986). By
adopting this 4:1 relationship we are again erring on
the side of caution (i.e., under-sampling).
3 The PSF defines the spatial influence or ‘spread’ of a zero-

dimensional point of light resulting from lens aberrations in the
sensor.

We also note, that if 14 represents detection, and
4:1 represents identification, then a fuzzy (i.e., not
specifically defined) range of scales (a maximum of)
16 times an object’s minimum detectable size exists,
where part of an object’s spatial influence is potentially discernible within a single image. This further
supports the hypothesis in the above section regarding
a limited range of object-specific spatial information
within a single image.
Upscaling strategy
In a previous study, Hay et al. (1997) evaluated OSU
against four resampling or scaling techniques traditionally included in remote sensing image-analysis
software. Over a gigabyte of data were analyzed
and upscaled from 1.5 m to 3 m, 5 m, and 10 m,
respectively, using nearest neighbor, bilinear interpolation, cubic convolution, non-overlapping averaging, and OSU. All upscaled images were evaluated
against (non-upscaled) data of the same scene originally collected at a 10-m spatial resolution. The
technique producing an upscaled image most visually
and statistically similar to the original 10-m image
was considered the most appropriate upscaling technique. Six thousand samples representing six different
forest classes were evaluated using the smallest rootmean-square-error (RMSE) results to represent the
best technique. Results indicate that OSU produced
the most visually and statistically accurate upscaled
images of those tested, with the lowest RMSE in 10
out of 18 classes over all forest types and ranges of
scale tested. In the eight times it did not obtain the
lowest RMSE, it produced six values with the second
lowest errors. Based upon these results OSU is considered the most appropriate upscaling technique, thus
it is used to resample the selected MI to a resolution
specified by Rh . To accomplish this, Rh is applied
to Equation 1, replacing the user-defined upscaling
kernel size (K). This iterative OSA and OSU strategy is then applied until VTw is larger than the image
dimensions.

Results
The original CASI image (OI ) spatially represents a
complex forest scene spanning a geographic extent
of 600 × 600 m. Spectrally it represents both the

481
Table 2. Image information and object-specific procedures for generating Figure 7.

SDn ISt Components


OI

SD0 IS1 = V1 , A1 , M1

 IS = V , A , M
2
2
2
2


U1

SD1 IS3 = V3 , A3 , M3

 IS = V , A , M
4
4
4
4


U
2

SD2 IS5 = V5 , A5 , M5

 IS = V , A , M
6
6
6
6


U3

SD3 IS7 = V7 , A7 , M7

 IS = V , A , M
8
8
8
8


U
4

IS9 = V9 , A9 , M9
SD4

 IS = V , A , M
10
10
10
10

OSAt

OSUn

MI Dimensions

Grain (m2 )

# Pixels

0

400 × 400
400 × 400
400 × 400

1.5
1.5
1.5

160000
160000
160000

1

250 × 250
250 × 250
250 × 250

2.4
2.4
2.4

62500
62500
62500

2

156 × 156
156 × 156
156 × 156

3.84
3.84
3.84

24336
24336
24336

3

98 × 98
98 × 98
98 × 98

6.14
6.14
6.14

9604
9604
9604

4

61 × 61
61 × 61
61 × 61

9.83
9.83
9.83

3721
3721
3721

1
2
3
4
5
6
7
8
9
10

Table 3. List of Object-Specific terms and abbreviations.
∀
∈
VTw(max)
AI , Aij , A2
EOs
IOs
ISt
K, SK
LTDv
MI , Mij , M2
OI
OSAt
OSUn
Pij
Rh
SDn
SDS
TSV
UI , U2
UPLM
VI , Vij , V2
VTw(max)
VTw(min)
VTw , VTij
WijK

For each. . .
Has membership in. . .
Local maximum variance defined with the variance threshold window
Area-image, Area value defined at (i, j), Area-image generated at OSA2
Edge-objects
Image-objects
Image-set generated at OSA iteration (t)
Upscaling kernel of (k ∗ k) user-defined dimensions, Sum of all Aij within K
The Landscape-threshold-domain, where (v) represents the number of landscape
thresholds defined by TSV within the SDS
Mean-image, Mean value defined at (i, j), Mean-image generated at OSA2
Original CASI image
Object-specific analysis at iteration (t)
Object-specific upscaling at the (nth ) upscaling iteration
Pixel located at row (i), column (j) in a 2D image
Resampling heuristic
Scale-domain, resulting from the (nth ) OSU iteration
Scale-domain-set
Total scene variance
Upscale-image, Upscale-image generated at OSA2
An upscaled pixel located at row L, column M, in the UI
Variance-image, Variance value defined at (i, j), Variance-image generated at OSA2
Local maximum variance defined with the variance threshold window
Local minimum variance defined with the variance threshold window
Variance threshold window, Pixel location (i, j) defined at the variance threshold
Object-specific weight defined at row (i), column (j) within K

482
minimum chlorophyll a reflectance signal4 , and the
absorption maximum of solvated chlorophyll a (Kirk
et al. 1978). In this study, it is also considered a
surrogate measure of vegetative ‘greenness’. When
the multiscale extension is applied to OI , the result
is a hierarchy of image-sets (SDn ), each consisting
of variance (VI ), area (AI ), and mean images (MI ),
with the same spatial resolution. As upscaling occurs,
the spatial resolution of the newly generated imagesets increase as do their scale domain subscripts i.e.,
SDn+1 . The iteration where OSU first takes place is referred to as SD1 . The image-set prior to this is SD0 - as
upscaling is not applied. Figure 7 illustrates image-sets
within the first four scale-domains (SD0−3 ), generated
from automatically applying 10 iterations of OSA, and
4 iterations of OSU to the original CASI image. The
procedures for producing these results are outlined in
Table 2, and are summarized as follows.
OSA was applied to the OI where object-specific
measures of maximum local variance were assessed
for every pixel resulting in the first image-set (V1 , A1 ,
and M1 ). OSA was then applied to the newly generated M1 , where object-specific measures of minimum
local variance were similarly assessed, resulting in the
second image-set (V2 , A2 , and M2 ). Together, these
image-sets and OI represent the first scale domain
(SD0 ), of which V2 , A2 , and M2 are illustrated in Figure 7. Based on the concepts described above, M2 was
automatically selected for upscaling to a resolution
defined by Rh . This resulted in a grain change from
1.5 m to 2.4 m and the generation of the first upscaled
image (U1 ). These procedures were then repeated for
the next 8 iterations, substituting in the appropriately
defined MI , Rh , and UI variables. In all cases, the resulting upscale images (U2−4 ) were used as the ‘seed’
images for OSA, from which new image-sets (IS3−10)
composing the additional scale-domains (SD1−4 ) were
generated. To facilitate visual comparisons5 between
the image-sets illustrated in Figure 7, each upscaled
image was resampled to 400 × 400 pixels. Resampling
was performed using nearest neighbor so that original
DN values were not changed. As a result, images in
latter scale-domains appear more ‘blocky’ than those
in SD0 .
4 Though radiometrically ‘close’, the low trough in spectra asso-

ciated with plants is nearer to 675 nm than to the spectral band
location (655–665 nm) defined in this data set.
5 All figures are 8 bit linearly scaled versions of 16 bit data that have
been enhanced for illustration. In the original images, far greater
visual clarity is achieved than in print.

As the grain size increased through the upscaling
process from 1.5 m to 9.83 m, the total number of
pixels in the image was reduced from 160,000, to
3,721. Object-specific analysis was stopped at OSA10 ,
as analyzing kernels contacted the borders of the image. Throughout the scaling process, the scene extent
remained constant at 600 × 600 m, but the physical dimensions of the generated images were systematically
reduced from 400 × 400, to 61 × 61 pixels. The visual
differences in information content resulting from these
procedures are illustrated in Figure 8, where U1−4 is
illustrated against the background of OI . We note that
OSU was applied to M2,4,6,8 to generate this upscale
composite.
Within each SDn , the VI represents a thresholdimage resulting from OSA. Essentially it illustrates
where the edges of differently sized objects have been
reached. Bright tones define areas of high variance
(object edges), while darker tones define areas of low
variance (object interiors) e.g. bright road edges vs.
dark young forest (image bottom) in V2 . Similarly,
each AI models the maximum spatial extent – or area
of influence – of its constituent objects at a specific
grain defined within the variance threshold kernel.
This important measure represents the unique (scalespecific) areas over which dominant landscape objects
exist, thus it is used to determine object-specificweights for scaling. Because image-objects are composed of similar pixels, they tend to be assessed within
smaller kernels, as their accompanying variance measures are small. This results in correspondingly small
area values, which are visually represented by dark areas. In A2 , dark tones within the mature stand (image
center) clearly correspond to individual tree crowns,
while the brighter surrounding values correspond to
edges composed of shadow and or understory pixels.
Visually, these results strongly support the validity of
objects-specific heuristics (at least over fine scales),
as individual trees illicit complex illumination/shade
effects on either side of their crown, yet both sides are
considered part of a single object (i.e., a dark tone).
In each MI every pixel represents a H-res member
of a newly detected image-object that exists at its next
(coarser) scale i.e., branches and leaves now become
part of a tree crown. Because these images are generated from average values calculated within specific
threshold kernels, they represent the dominant image
structure defined at a specific spatial resolution within
a unique scale-domain. To enhance interpretation of
the overall structural evolution of each MI composing
SD1−4 , we have applied a simple linear color table, as

483

Figure 7. Scale domain sets (SDS0−3 ) consisting of variance (VI ), area (AI ), and mean (MI ) images.

484
printed gray-tone gradations are more difficult to distinguish. In each MI , black and purple represent highdensity vegetation, dark blue represents low-density
vegetation, and light blue-green represents the gradient between sparsely vegetated and non-vegetated
areas. Clear-cut areas with varying amounts of vegetation range from green-yellow, where colors represent
low-density invading grasses and shrubs on partially
exposed soils, to orange-red, representing the maximum scene brightness resulting from fully exposed
soils.
As the spatial resolution of each SDn changes, each
VI , AI , and MI visually delineate newly defined scalespecific structures that represent the dominant objects
emergent at these scales. In SD0 a large amount
of recognizable object structure is explicitly defined.
In particular, individual tree crowns, their shadows,
canopy gaps, patches of exposed soil and vegetation,
road edges, and vegetation along roads are highly discernible in both V2 and A2 . In SD1 we see an obvious
evolution from individual crown structures within the
mature stand (as defined in V2 and A2 ), to larger sized
objects (dark patches) that correspond to areas of high
stand densities and include reflective characteristics
from crowns, shadows, and understory. At this scale,
the (highly reflective central) gravel road is influenced
by the spectral characteristics of the surrounding vegetation, causing it to change from green-yellow (as
depicted in M2 ) to a light blue (in M4 ). It is also
important to note the increasing spatial effect (i.e.,
larger areas of bright tones in A4 ) appearing along
the edge of vegetated and non-vegetated areas. In V4 ,
this is represented by bright linear features around
(darker) objects, and will be referred to further in the
Discussion section.
In SD2−3 we see a dramatic change in the overall scene composition from the previous scale-domain
sets. Here, the images clearly illustrate a distinct evolution within three dominant object groups: C.Cut (including roads, grasses, and bare soil depicted), youngforest (which includes young and juvenile classes),
and mature forest. The net result is an increasing spatial and spectral encroachment of clear-cut, and low
vegetation density areas within locations that were initially densely vegetated. This is most apparent in the
upper right quadrant of each image, where the spatial
influence of C.Cut, and lower density vegetation (i.e.,
young forest) increase at the expense of mature forest.

Figure 8. This upscale image (U1−4 ) composite illustrates the different image extents resulting from four iterations of object-specific
upscaling (OSU).

Discussion
What exists between the end of one image-object and
the beginning of another?
We suggest that multiscale image-object thresholds are
often far more ‘fuzzy’ or less discrete than the term
threshold commonly implies. This is because the pixels used to evaluate image-thresholds are themselves a
hemispherical integration of reflected light, which represents the non-linear interaction of entities existing
over different scales. For example, a single ‘threshold’
pixel defining the extent of a tree-crown may share its
composition with a portion of this crown’s edge, the
neighboring crown shadow, understory, and partial reflectance from near-by exposed soil. Therefore, rather
than a pixel being part of a nested hierarchy of discrete
image-objects that spatially lie adjacent to each other
through scale, there exists instead, a unique range of
scales between the end of one image-object, and the
beginning of another, that is composed of integrated
‘edge’ pixels. We refer to the species of objects that
populate this ‘edge-space’ as edge-objects (EOs), and
suggest that an example of their signal is illustrated in
Figure 5, between A–B, C–D, and E–F.
Conceptually, EOs exist within a varying range of
scales located on the ‘other-side’ of discrete imageobject frontiers or boundaries, but due to their digital

485
nature6 they actually share part of their spectral composition with a non-linear integrated fraction of the
edge pixels they abut. As a consequence, EOs will
always be L-res which means they will be represented
by relatively large VI and AI measures, as they are
unable to be defined within the range of scales commonly used to assess image-objects (see Figure 7). For
example, during OSA1 , visual and statistical output
generated at each increment in window size indicated
that 99% of OI was processed within a window size of
29 × 29. Yet the remaining 1% required analysis up to
a window size of 63 × 63. In addition, this 1% of pixels did not visually correspond to spatially meaningful
image-objects within OI . Instead, they represented
edge locations between recognizable IOs. A similar
trend was found in all additional iterations throughout
the OSA process.
To ensure that spatially dominant image-objects
will emerge through multiscale analysis, rather than
EOs, we confirm that inverse area values (which favor image-objects) are used to define all OSU weights.
And yet, EOs appear to spatially dominate at coarser
grain sizes, rather than recognizable image-objects
(see Figure 7). We suggest two plausible solutions
for this condition. Either EOs represent real landscape structure(s), or they are artifacts resulting from
inappropriate OSA heuristics.
Strong support that OSA heuristics work well on
recognizable image-objects is provided by SD0 in
Figure 7, where individual tree crowns, road edges,
canopy gaps, and barren areas have been explicitly
delineated. When these results are considered in relation to the evaluation conducted during heuristic
development, we are confident that the heuristics work
well. The second solution is that EOs are actually
image-objects that represent real multiscale landscape
structure that we may not be familiar with from a
single-scale perspective.
If edge-objects (EOs) are real, what landscape
phenomenon do they model?
As Wu and Qi (2000) point out, it is not always clear
whether the effect of changing scale is an artifact due
to the improper use of analytical methods, an indication of the scale multiplicity of ecological systems, or
neither of the two. If for a moment we consider that
6 Within a digital scene, an image-edge or threshold is not a 1D-line

composed of zero-dimensional points lying between two or more
pixels, but rather a 3D pixel (i.e., x, y, DN) that must exist in the
same location as one of the points it is trying to segregate.

EOs are real landscape entities rather than image artifacts, what do they structurally represent? By their
very nature, we know that they are not image-objects
with obvious real-world counterparts, if they were, we
would recognize them. Obviously we need to evaluate
EOs with a different conceptual perspective. What we
do know is that EOs exist in the ‘edge-space’ between
image-objects. Visual analysis of Figure 7 reveals a
spatial evolution of increasing perimeter for C.Cut,
gravel-road, and barren-ground, that extends far beyond their initial physical boundaries (see Figure 4a).
When these changes are considered in relation to the
scale-dependent manner in which OSA functions, it
is highly plausible that the evolution of EOs models
the scale-dependent change(s) occurring at, or within,
ecotones.
Although the study of ecotones is complicated by
the diversity of interpretation regarding their nature,
we adopt the definition of Holland (1988), where the
transition zone between adjacent patches is recognized
as an ecotone. In OSA, image-objects correspond to
scale-dependent patches within a landscape mosaic,
thus EOs correspond to their ecotones. A serious
challenge with ecotone detection is the subjectivity
inherent with identifying boundaries along gradually
changing ecolines. Here the difficulty involves dividing a zone of ‘continuous’ variation into compartments. As Johnson et al. (1992) indicate, even when
statistically significant differences exist between individual compartments, the boundaries between them
may not represent true ecotones. Instead, ecotones
span the range between these two extremes. In addition, boundary distinctness is scale dependent, thus
users are also faced with the subjectivity of determining the most appropriate scale to assess the scene,
which in turn effects the delineation of ecotones.
One of the true benefits of imaging spectrometry is the ability to explicitly link specific spectral
characteristics with physiological properties (Wessman et al. 1989). If the idea of EOs as ecotones is
linked with the spectral characteristics of the original
CASI image (i.e., a surrogate measure of vegetative
‘greenness’) it is further plausible to hypothesize that
EOs defined in OI may be a visual analogue of what
is referred to as ‘depth-of-edge influence’, or ‘edge
width’ (Chen 1999). Depth-of-edge influence is associated with microclimatic zones across abrupt edges
in the landscape, and can result in broad areas of
edge influence, which constitute a significant portion
of (unaccounted) fragmentation in a landscape. The
phenomenon varies over time and with edge charac-

486
teristics, and can extend four to six tree heights into
the forest from a recent clear-cut edge. Notably, edgewidth value varies according to different tree species,
ranging from 60 m in Eastern Red Pine/White Pine to
over 400 m in Pacific N.W. Douglas-fir forests (Chen
1999). This ‘EO = edge-width’ hypothesis is further
supported by the fact that OI is a high-resolution scene
of a (then) recently clear-cut site on southern Vancouver Island, where the dominant tree species in all
three-forest classes (Mature, Young and Juvenile) are
Pacific N.W. (Coastal) Douglas Fir. However, it is
important to note that no microclimate data were available to corroborate this hypothesis. Nevertheless, this
provides an excellent example of how object-specific
analysis offers new insight into linking and questioning the relationships between landscape processes and
multiscale landscape patterns, that may not have been
possible without such a multiscale perspective.
Can an OSA perspective be used to define
landscape-scale thresholds?
Through the iterative OSA and OSU process, the patterns generated within a SDS represent an evolution of
image-objects from small-scale entities such as individual tree-crowns, to larger ‘landscape’ sized objects
that will eventually dominate the entire image. From
the results in Figure 7 it is clear that between SD1
and SD2 , recognizable image-objects stopped being
generated, and unfamiliar EOs began to emerge and
dominate the scene. We suggest that this change in
spatial dominance, from image-objects to EOs, corresponds to crossing a landscape-scale threshold, and
that it can be defined in a similar fashion as individual
image-object thresholds.
Recall that when applying OSA to detect objectspecific thresholds, each pixel is evaluated as part
of an individual image-object. Therefore, to detect a
landscape-scale threshold within an OSA framework,
all image-objects and EOs within a scene are evaluated
as being part of a larger scene-object (i.e., a landscapescale threshold-object) that spatially dominates the
entire image/landscape being assessed. This is operationalized by evaluating the total scene variance
(TSV) for each image in a nested hierarchy, where
each image represents the same study area, but at a
different grain size. The resulting signal is then plotted, and modeled revealing distinct saddles and peaks,
which correspond to the beginning and end scales of
landscape-scale threshold-objects. Essentially this is
scale variance analysis as described earlier, except

that within an OSA framework, the nested hierarchy
corresponds to image-sets generated at each OSA iteration, and images representing different grain sizes are
generated only at odd-numbered iterations (except for
OSA1 ). In addition, TSV is defined for each varianceimage rather than each mean-image as object-specific
structures are explicitly defined in VI , while in MI
such structures are smoothed. In simple terms, these
procedures correspond to evaluating the total difference in the variation resulting from the individual
image-objects composing a scene through all possible
object-specific scales of analysis.
To better understand the total scene variance
and corresponding scene/landscape structure through
scale, TSV values generated for each VI at odd numbered iterations7 are modeled with a high order polynomial (R 2 = 0.999), and the resulting curve [Poly.
(TSV)] is illustrated in Figure 9. We note that while
the shape of this cure is similar to that found in Figure 5, it must be assessed with caution past iteration
8, as OSA8−10 kernels required analysis over larger
window sizes than the available image dimensions.
This indicates that the pixels being assessed were part
of a larger-scale image-object that existed beyond the
extent defined by the image. Visual analysis of Poly.
(TSV) reveals a saddle at iteration 3 and a peak at iteration 6 indicating the beginning and end range of the
first landscape-scale threshold-object. It is also possible that another landscape scale threshold begins at
or after OSA11 . Recall from Table 2, that OSA3−4
are members of SD1 . When compared with the results in Figure 7, the first landscape-sized threshold
corresponds explicitly to the visual changes between
SD1 and SD2 , supporting the idea that OSA can be
used to evaluate a full-range of landscape thresholds
ranging from small-scale image-objects to large-scale
landscape structures.

Conclusion
From a multiscale perspective a scale-domain set may
be visualized as a hierarchical scaling ladder (Wu
1999), and each SDn may be visualized as an individual rung, separated by unequal spaces that are
specific to the range of scales assessed within the ISt
that composes it. Alternatively, since Figure 9 supports the detection of landscape-thresholds between
7 We note that values generated at even-numbered iterations produced a very similar curve, transposed by one iteration in the
x-axis.

487

Figure 9. Total Scene Variance (TSV) defined at odd-numbered object-specific analysis (OSA) iterations. Poly.(TSV) represents TSV values
modeled by a high order polynomial curve (R 2 = 0.999) that is similar to the curve illustrated in Figure 5.

adjacent SDn , it may be more reasonable to include
SDn as a subset of a higher-order set we refer to
as a landscape-threshold-domain (LTDv ), where the
subscript (v) represents the number of different landscape thresholds defined by TSV within the SDS. Thus
equation 4 should be augmented as follows:
Pij ∈ IOs ∈ ISt ∈ SDn ∈ LTDv ∈ SDS

(5)

As a result, it may be more appropriate to consider the landscape represented by a linked group of
different sized scaling ladders, where each ladder corresponds to a specific LTDv , rather than a single hierarchical scaling ladder as Wu (1999) suggests. Though
originating from different starting points, we suggest
that a multiscale OSA and OSU approach provides
a methodological framework that is complimentary
to the described theory, and techniques required by
the Hierarchical Patch Dynamics Paradigm (HPDP)
(Wu and Loucks 1995). HPDP provides a link between the patch dynamic perspectives and hierarchy
theory that emphasizes multiscale properties of pattern
and process dynamics in ecological systems. In this
paradigm, individual patches are considered the fundamental structural and functional units. In OSA these
primitives correspond to image-objects, whose spatial
dimensions and influence can be defined and aggregated to unique coarser scales (i.e., OSU), specified
by the dominant entities (AI ) composing a scene.

If at multiple image scales, the spatial extent of
dominant AI patterns strongly corresponds to geographic areas over which known processes are dominant (i.e., soils, slope, aspect), these areas may be
selected as locations over which scale-dependent ecological models could be developed, or data explicitly
translated to and from (Holling 1992). King (1990)
identifies four general methods of translating ecological models to larger scales: (1) lumping, (2) direct
extrapolation, (3) extrapolation by expected value, and
(4) explicit integration. In particular, direct extrapolation could benefit from OSA because it involves
explicitly running a small-scale model for a set of discrete elements, scaling the output of each element by
the area represented, then combining the outputs to
represent the large-scale system.
If we consider that the OSA and OSU heuristics
are sufficiently robust, and that MAUP effects are minimized – through adopting an entity, or object-specific
approach – then the complex patterns forming at each
OSA iteration represent the emergence of real world
structures existing, or imbedded at different scales
within a single scale of imagery. Good reason exists
to consider this a sound supposition, as (VI ) and (AI )
strongly correspond to real world scene-components,
thus the heuristics defining image-object thresholds
are being met. As threshold patterns emerge at each
iteration, and their specific resolutions and extents are
defined, the ideal situation would be for remote sens-

488
ing data – representing surrogate ecological measures
[such as leaf area index (LAI), or fraction of photosynthetically active radiation, (FPAR)] – to be scaled with
OSU and used as inputs into unique ecological models operating over the spatial extents defined by the
corresponding AI (Freidl 1997). Alternatively, model
development and data type selection could be guided
by the OSA scale-domains and landscape threshold
patterns generated. If iterated OSA and OSU results
correspond to field data over a range of known scales,
precedent exits upon which to assess OSA and OSU
results at coarser unverifiable image scales. At present,
object topology is not embedded within the analyzing
routines, but it is envisioned in subsequent versions,
which will provide multiscale image-object output for
use in geographic information systems.
In this paper we introduce a multiscale framework
for analysis and upscaling that when applied to remote
sensing imagery reduces the effects of MAUP by incorporating an object-specific approach. By considering landscapes as hierarchical structures and adopting
this multiscale framework, the patterns of landscape
objects operating at, and over, unique spatial scales
may be thematically and numerically quantified by
their spatial dominance. While aware that the entities that emerge in a data set are scaled by virtue of
the observation protocol and the filters applied to the
data during analysis, we suggest that multiscale OSA
and OSU offers a potentially powerful framework for
improved understanding of scale-specific landscape
patterns. In particular, multiscale OSA may assist
in defining critical landscape thresholds, domains of
scale, ecotone boundaries, and the grain and extent
at which scale-dependent ecological models could be
developed and applied.
This paper provides only a small sample of the
potential of multiscale OSA tested over a relatively
fine geographic area. The next step is to apply these
ideas over a larger-extent fine-grained scene, where
sufficient ancillary data exist so that results may be
fully verified over numerous spatial scales. To facilitate this, analysis is presently underway in the complex
agro-forested Haut-Saint-Laurent region of Quebec to
examine how landscape fragmentation and connectedness change through scale, and what their implications
are for landscape management (Bouchard and Domon
1997; Pan et al. 2000). Our primary objective will
be to apply the described object-specific framework
to H-res Ikonos satellite data (acquired in September,
2000) that represents an 11 km × 11 km scene, and
evaluate the multiscale results against a database rep-

resenting more than 15 consecutive years of intensive
field studies and research.

Acknowledgements
This work has been supported by a Biology graduate scholarship of excellence from the University of
Montréal and a GREFi Ph.D. Scholarship awarded
to Mr Hay, by the Ministry of Natural Resources
Canada through its Human Resources Planning and
Training Program, and by a team grant awarded to
Dr A. Bouchard and Dr D. Marceau from FCAR,
Gouvernement du Québec. We also express appreciation to Forestry Canada for the CASI imagery, Dr
Marie Josée-Fortin for her assistance with algorithm
notation, and to three anonymous referees for their
constructive comments.

References
Allen, T.F.H. and Hoekstra, T.W. 1991. Role of heterogeneity in
scaling of ecological systems under analysis. In Ecological Studies 86: Ecological Heterogeneity. pp. 47–68. Edited by J. Kolasa
and S.T.A. Pickett, Springer-Verlag.
Allen, T.F.H. and Starr, T.B. 1982. Hierarchy Perspective for
Ecological Complexity. University of Chicago Press, Chicago,
310 pp.
Amrhein, C. and Reynolds, H. 1996. Using spatial statistics to
assess aggregation effects. Geogr. Syst.3: 143–158.
Benson, B.J. and MacKenzie, M.D. 1995. Effects of sensor spatial
resolution on landscape structure parameters, Landscape Ecol.
10: 113–120.
Bian, L. and Walsh, S.J. 1993. Scale dependencies of vegetation
and topography in a mountainous environment of Montana, The
Professional Geographer 45: 1–11.
Bouchard, A. and Domon, G. 1997. The transformation of the
natural landscapes of the Haut-Saint-Laurent (Québec) and its
implication on future resources management. Landscape Urban
Plan. 37: 99–107.
Caldwell, M.M., Matson, P.A., Wessman, C. and Gamon, J. 1993.
Prospects for scaling, in Scaling Physiological Processes: Leaf
to Globe. pp. 223–230. Academic Press.
Chen. J, Saunders, S.C., Crow, T.R., Naiman, R.J. 1999. Microclimate in forest Ecosystems and Landscape Ecology. Bioscience
49: 288–297.
Coveney, P. and Highfield, R. 1991. The Arrow of Time. Flamingo
Press, London, 378 pp.
Cullinan, V.I., Simmons, M.A. and Thomas, J.M. 1997. A bayesian
test of hierarchy theory: scaling up variability in plant cover from
field to remotely sensed data. Landscape Ecol. 12: 273–285.
Curran, P.J. and Atkinson, P.M. 1998. Geostatistics and Remote
Sensing. Progr. Phys. Geogr. 22: 61–78.
DeFries, R.S., Townshend, J.R. and Los, S.O. 1997. Scaling
land cover heterogeneity for global atmosphere-biosphere models. pp. 231–246. In Scale in Remote Sensing and GIS, Lewis
Publishers.

489
Dudley, G. 1991. Scale, aggregation, and the modifiable areal unit
problem. The Operational Geographer 9: 28–33.
Duggin, M.J. and Robinove, C.J. 1990. Assumptions implicit in
remote sensing data acquisition and analysis. Int. J. Remote
Sensing 11: 1669–1694.
Ehleringer, J.R and Field, C.B. (Eds), 1993. Scaling Physiological
Processes: Leaf to Globe. Academic Press, 388 pp.
Fotheringham, A.S. 1989. Scale-independent spatial analysis.
pp. 221–228. In Accuracy of Spatial Databases, Taylor and
Francis.
Fotheringham, A.S. and Wong, D.W.S. 1991. The modifiable areal
unit problem in multivariate statistical analysis. Environment and
Planning A, 23: 1025–1044.
Freidl, M.A. 1997. Examining the Effects of Sensor Resolution
and Sub-Pixel Heterogeneity on Spectral Vegetation Indices: Implications for Biophysical Modeling. pp. 113–139. In Scale in
Remote Sensing and GIS, Lewis Publishers.
Friedl, M.A., Davis, F.W., Michaelsen, J. and Moritz, M.A. 1995.
Scaling and uncertainty in the relationship between the NDVI
and land surface biophysical variables: An analysis using a
scene simulation model and data from FIFE. Remote Sensing of
Environment 54: 233–246.
Gardner, R.H. 1998. Pattern, Process, and the Analysis of Spatial
Scales. pp. 17–34. In Ecological Scale Theory and Applications.
Columbia University Press.
Gardner, R.H., Cale, W.G. and O’Neill, R.V. 1982. Robust analysis
of aggregation error. Ecology 63: 1771–1779.
Hay, G.J., Niemann, K.O. and Goodenough, D.G. 1997. Spatial
thresholds, image-objects, and upscaling: A multiscale evaluation. Remote Sensing of Environment 62: 1–19.
Hay, G.J., Niemann, K.O. and McLean, G.F. 1996. An objectspecific image-texture analysis of H-resolution forest imagery.
Remote Sensing of Environment 55: 108–122.
Holland, M.M, 1988. SCOPE/MAP technical consultations on
landscape boundaries. Biol. Intl. 17: 47–106.
Holling, C.S. 1992. Cross-scale morphology, geometry, and dynamics of ecosystems. Ecol. Monogr. 62: 447–502.
Hunt, L. and Boots, B. 1996. MAUP effects in the principal axis
factoring technique, Geogr. Syst. 3: 101–121.
Jarvis, P.G. 1995. Scaling processes and problems. Plant Cell
Environ. 18: 1079–1089.
Jelinski, D.E. and Wu, J. 1996. The modifiable areal unit problem
and implications for landscape ecology. Landscape Ecol. 11: 29–
140.
Jensen, J.R. 1986. Introductory Digital Image Processing, PrenticeHall, Englewood Cliffs, NJ, 379 pp.
Johnston, C.A., Pastor, J. and Pinay, G. 1992. Quantitative Methods for studying Landscape Boundaries. In Landscape Boundaries. Consequences for Biotic Diversity and Ecological flows.
pp. 107–125. Springer-Verlag.
Kay, J.J. and Schneider, E.D. 1995. Embracing Complexity: The
Challenge of the Ecosystem Approach. pp. 49–59. In Perspectives on Ecological Integrity, Kluwer, Dordrecht.
King, A.W. 1999. Hierarchy Theory and the Landscape . . . Level?
Or: Words do Matter. Issues in Landscape Ecology. pp. 6–
9. Edited by J. Wiens, M. Moss. International Association for
Landscape Ecology. Fifth World Congress. Snowmass Village,
Colorado, USA.
King, A.W. 1990. Translating models across scales in the landscape.
In Quantitative Methods in Landscape Ecology, pp. 479–517,
Springer-Verlag.
Kirk, O. and Tilney-Basset, R.A.E. 1978. The Chlorophylls. The
Plastids. Their Chemistry, structure, growth and inheritance.
pp. 64–89. Freeman & Co. LTD.

Levin, S.A., 1992. The problem of pattern and scale in ecology.
Ecology 73: 1943–1967.
Mandelbrot, B. 1967. The Fractal Geometry of Nature. Science 156:
636–642.
Marceau, D.J. 1999. The scale issue in the social and natural
sciences. Can. J. Remote Sensing 25: 347–356.
Marceau, D.J. and Hay, G.J. 1999a. Contributions of remote sensing
to the scale issues. Can. J. Remote Sensing 25: 357–366.
Marceau, D.J. and Hay, G.J. 1999b. Scaling and Modelling in
Forestry: Applications in Remote Sensing and GIS. Can. J.
Remote Sensing 25: 342–346.
Marceau, D.J., 1992. The problem of scale and spatial aggregation
in remote sensing: An empirical investigation using forestry data.
Unpublished Ph.D. thesis, Department of Geography, University
of Waterloo, 180 pp.
Marceau, D.J., Howarth, P.J. and Gratton, D.J. 1994. Remote sensing and the measurement of geographical entities in a forested
environment; Part 1: The scale and spatial aggregation problem.
Remote Sensing Environ. 49: 93–104.
Meentemeyer, V. 1989. Geographical perspectives of space, time,
and scale. Landscape Ecol. 3: 163–173.
Moellering, H. and Tobler, W. 1972. Geographical variances. Geogr.
Analysis 4: 34–64.
Moody, A. and Woodcock, C.E. 1995. The influence of scale and
the spatial characteristics of landscapes on land-cover mapping
using remote sensing. Landscape Ecol. 10: 363–379.
Nicolis, G. and Prigogine, I. 1989. Exploring Complexity. W.H.
Freeman, New York, 313 pp.
O’Neill, R.V. and King, A.W. 1998. Homage to St. Michael; Or,
Why are there so many books on Scale? In Ecological Scale
Theory and Applications. pp. 3–15. Columbia University Press.
O’Neill, R.V., De Angelis, D.L., Waide, J.B. and. Allen, T.F.H.
1986. A hierarchical concept of ecosystems. Princeton University Press, Princeton, New Jersey, 262 pp.
O’Neill, R.V., Hunsaker, C.T., Timmins, S.P., Jackson, B.L., Jones,
K.B., Ritters, K.H. and Wickham, J.D. 1996. Scale problems
in reporting landscape patterns at the regional scale, Landscape
Ecol. 11: 169–180.
O’Neill, R.V., Johnson, A. R. and King, A.W. 1989. A hierarchical
framework for the analysis of scale. Landscape Ecol. 3: 193–205.
Openshaw, S. 1981. The modifiable areal unit problem. In Quantitative Geography: A British View. pp. 60–69. Routledge and
Kegan Paul, London.
Openshaw, S. 1984. The Modifiable Areal Unit Problem. Concepts and Techniques in Modern Geography (CATMOG) No. 38,
40 pp.
Openshaw, S. and Taylor, P. 1979. A million or so correlation coefficients: three experiments on the modifiable areal unit problem.
In Statistical Applications in the Spatial Sciences. pp. 127–144.
London Pion.
Pan, D., Domon, G., Marceau, D.J. and Bouchard, A. 2001. Spatial
pattern of coniferous and deciduous forest patches in an Eastern
North America agricultural landscape: The influence of land-use
and physical attributes. Landscape Ecol. 16: 99–110.
Pax-Lenney, M. and Woodcock, C.E. 1997. The effect of spatial resolution on the ability to monitor the status of agricultural lands.
Remote Sensing Environ. 61: 210–220.
Slater, P.N. 1980. Remote Sensing: Optics and Optical Systems.
Addison-Wesley, 575 pp.
Souriau, M. 1994. Scaling and physical thresholds: The case of
continental topography. Int. J. Remote Sensing 15: 2403–2408.
Stewart, J.B., Engman, E.T., Feddes, R.A. and Kerr, Y.H. 1998.
Scaling up in hydrology using remote sensing: summary of a
Workshop. Int. J. Remote Sensing 19: 181–194.

490
Townsend, P.A. 2000. A Quantitative Fuzzy Approach to Assess
Mapped Vegetation Classifications for Ecological Applications.
Remote Sensing of Environ. 72: 253–267.
Treitz, P. and Howarth. P. 2000. High Spatial Resolution Remote
Sensing Data for Forest Ecosystem Classification: An Examination of Spatial Scale. Remote Sensing Environ. 72: 268–289.
Turner, S.J., O’Neill, R.V., Conley, W., Conley, M.R. and
Humphries, H.C. 1991. Pattern and Scale: Statistics for Landscape Ecology. In Quantitative Methods in Landscape Ecology.
pp. 19–49. Springer Verlag.
Ustin, S.L., Smith, M.O. and Adams, J.B. 1993. Remote sensing
of ecological processes: A strategy for developing and testing
ecological models using spectral mixture analysis. In Scaling
Physiological Processes: Leaf to Globe. pp. 339–357. Academic
Press.
Walsh, S.J., Moody, A., Allen, T.R. and Brown, D.G. 1997. Scale
dependence of NDVI and its relationship to mountainous terrain.
In Scale in Remote Sensing and GIS, Lewis Publishers pp. 27–
55.

Wessman, C.A., Aber, J.D. and Peterson, D.L. 1989. An evaluation
of imaging spectrometry for estimating forest canopy chemistry.
Int. J. Remote Sensing 10: 1293–1316.
Wiens, J.A. 1989. Spatial scaling in ecology. Functional Ecol. 3:
385–397.
Woodcock, C.E. and Strahler, 1987. The factor of scale in remote
sensing. Remote Sensing Environ. 21: 311–332.
Wu, J. 1999. Hierarchy and Scaling: Extrapolating Information
Along A Scaling Ladder. Can. J. Remote Sensing 25: 367–380.
Wu, J. and Loucks, O.L. 1995. From balance of nature to hierarchical patch dynamics: a paradigm shift in ecology. Quater. Rev.
Biol. 70: 439–466.
Wu, J. and Qi, Y. (in press). Dealing with scale in landscape
analysis: An overview. Geogr. Inform. Sci., 6: 1–5.
Wu, J., Jelinski, D. E., Luck, M. and Tueller, P.T. (in press). Multiscale Analysis of Landscape Heterogeneity: Scale Variance and
Pattern Metrics. Geogr. Inform. Sci., 6: 6–19.

